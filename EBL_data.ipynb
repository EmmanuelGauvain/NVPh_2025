{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75f7540b",
   "metadata": {},
   "source": [
    "\n",
    "# 1) BDV & trends - Collect and prepare data\n",
    "**Goal:** This notebook creates a clean dataset from existing sources.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e170b62f",
   "metadata": {},
   "source": [
    "\n",
    "## 1) clean AnAge\n",
    "Clean the AnAge dataset in order to test the link between max longevity residual and EBL count.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6c434a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "\n",
    "ANAGE_CSV = \"anage.csv\"  \n",
    "\n",
    "OUTPUT_DIR = \"outputs\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1556af16-160e-4e9c-a39d-1b37744c50de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Wrote cleaned file: anage_fixed.csv\n",
      "Columns: ['Scientific name', 'Order', 'Adult weight (g)', 'Maximum longevity (yrs)']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scientific name</th>\n",
       "      <th>Order</th>\n",
       "      <th>Adult weight (g)</th>\n",
       "      <th>Maximum longevity (yrs)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Daphnia pulicaria</td>\n",
       "      <td>Diplostraca</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Drosophila melanogaster</td>\n",
       "      <td>Diptera</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apis mellifera</td>\n",
       "      <td>Hymenoptera</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cardiocondyla obscurior</td>\n",
       "      <td>Hymenoptera</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lasius niger</td>\n",
       "      <td>Hymenoptera</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Scientific name        Order  Adult weight (g)  \\\n",
       "0        Daphnia pulicaria  Diplostraca               NaN   \n",
       "1  Drosophila melanogaster      Diptera               NaN   \n",
       "2           Apis mellifera  Hymenoptera               NaN   \n",
       "3  Cardiocondyla obscurior  Hymenoptera               NaN   \n",
       "4             Lasius niger  Hymenoptera               NaN   \n",
       "\n",
       "   Maximum longevity (yrs)  \n",
       "0                     0.19  \n",
       "1                     0.30  \n",
       "2                     8.00  \n",
       "3                     0.50  \n",
       "4                    28.00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re\n",
    "import csv\n",
    "\n",
    "RAW = \"anage.csv\"                       # original file\n",
    "FIXED = \"anage_fixed_new.csv\"           # clean file we'll generate\n",
    "\n",
    "def fix_line(line: str) -> str:\n",
    "    # 1) trim whitespace/newlines\n",
    "    s = line.rstrip(\"\\r\\n\")\n",
    "\n",
    "    # 2) remove leading outer quote if present\n",
    "    if s.startswith('\"'):\n",
    "        s = s[1:]\n",
    "\n",
    "    # 3) remove trailing sequence of quote + semicolons (e.g., '\";;;;')\n",
    "    s = re.sub(r'\";*$', '', s)\n",
    "\n",
    "    # 4) inside the remaining text, turn any '\";\"' (semicolon between quoted tokens) into a space inside the quotes\n",
    "    #    e.g.  ...\"Fruit\";\"fly\"...  -> ...\"Fruit fly\"...\n",
    "    s = s.replace('\";\"', '\" \"')\n",
    "\n",
    "    # 5) collapse doubled quotes (\"\") to single \"\n",
    "    s = s.replace('\"\"', '\"')\n",
    "\n",
    "    # Done. At this point, commas are true delimiters; fields remain quoted as normal CSV.\n",
    "    return s\n",
    "\n",
    "# Pass 1: fix each line and write a new CSV\n",
    "with open(RAW, \"r\", encoding=\"utf-8\", errors=\"replace\") as fin, \\\n",
    "     open(FIXED, \"w\", encoding=\"utf-8\", newline=\"\") as fout:\n",
    "    for line in fin:\n",
    "        fixed = fix_line(line)\n",
    "        # skip empty lines\n",
    "        if fixed.strip():\n",
    "            fout.write(fixed + \"\\n\")\n",
    "\n",
    "print(f\"✅ Wrote cleaned file: {FIXED}\")\n",
    "\n",
    "# Pass 2: load the cleaned CSV with pandas\n",
    "df = pd.read_csv(FIXED)\n",
    "\n",
    "# --- Build 'Scientific name' and coerce numeric columns ---\n",
    "\n",
    "def find_col(df, candidates):\n",
    "    norm = {c: re.sub(r\"[^a-z0-9]+\",\"\", c.lower()) for c in df.columns}\n",
    "    for cand in candidates:\n",
    "        key = re.sub(r\"[^a-z0-9]+\",\"\", cand.lower())\n",
    "        for c,n in norm.items():\n",
    "            if n == key:\n",
    "                return c\n",
    "    for cand in candidates:\n",
    "        key = re.sub(r\"[^a-z0-9]+\",\"\", cand.lower())\n",
    "        for c,n in norm.items():\n",
    "            if key in n:\n",
    "                return c\n",
    "    raise KeyError(f\"None of {candidates} found. Columns: {list(df.columns)}\")\n",
    "\n",
    "def to_num(series):\n",
    "    return pd.to_numeric(\n",
    "        (series.astype(str)\n",
    "               .str.replace(\"\\u00A0\",\"\", regex=False)  # NBSP\n",
    "               .str.replace(\" \", \"\", regex=False)      # thousands spaces\n",
    "               .str.replace(\",\", \".\", regex=False)),   # decimal comma -> dot\n",
    "        errors=\"coerce\"\n",
    "    )\n",
    "\n",
    "\n",
    "class_col   = find_col(df, [\"Class\"])\n",
    "order_col   = find_col(df, [\"Order\"])\n",
    "genus_col   = find_col(df, [\"Genus\"])\n",
    "species_col = find_col(df, [\"Species\"])\n",
    "life_col    = find_col(df, [\"Maximum longevity (yrs)\",\"Maximum.longevity.yrs\"])\n",
    "mass_col    = find_col(df, [\"Adult weight (g)\",\"Body.mass.g\",\"Adult.body.mass.g\"])\n",
    "\n",
    "df[\"Scientific name\"] = (\n",
    "    df[genus_col].astype(str).str.strip() + \" \" +\n",
    "    df[species_col].astype(str).str.strip()\n",
    ")\n",
    "\n",
    "df[\"Maximum longevity (yrs)\"] = to_num(df[life_col])\n",
    "df[\"Adult weight (g)\"]        = to_num(df[mass_col])\n",
    "\n",
    "anage = df[[\"Scientific name\", order_col, \"Adult weight (g)\", \"Maximum longevity (yrs)\"]].rename(\n",
    "    columns={order_col: \"Order\"}\n",
    ")\n",
    "\n",
    "print(\"Columns:\", list(anage.columns))\n",
    "display(anage.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0033473",
   "metadata": {},
   "source": [
    " ## 2) clean EBL count\n",
    "We'll take data from Kawasaki et al.'s 2021 PNAS paper and output a clean \"EBL-count_per_species\" CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "10d41e7a-8c79-483b-b195-00d99ec77c3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: EBL_counts_per_species.csv\n"
     ]
    }
   ],
   "source": [
    "PNAS_XLSX = \"pnas.2026235118.sd01.xlsx\"   # this file comes from the Kawasaki et al. (2021) paper\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "# Read the sheet; this file has a 2-row explanatory header, real header is on row index 1\n",
    "raw = pd.read_excel(PNAS_XLSX, sheet_name=\"Sheet1\", header=None)\n",
    "\n",
    "# Find the header row by locating the cell that says \"Host species\"\n",
    "hdr_row = raw.index[raw.apply(lambda r: r.astype(str).str.contains(r\"\\bHost species\\b\", na=False)).any(axis=1)][0]\n",
    "header = raw.iloc[hdr_row].tolist()\n",
    "df = raw.iloc[hdr_row+1:].copy()\n",
    "df.columns = header\n",
    "\n",
    "# Keep minimal columns: EBL Name (contains the genus) and Host species\n",
    "df = df.rename(columns={\"Name\":\"EBL_Name\", \"Host species\":\"Host_species\"})\n",
    "df = df[[\"EBL_Name\", \"Host_species\"]].dropna(subset=[\"EBL_Name\",\"Host_species\"])\n",
    "\n",
    "# Extract the bornavirus genus encoded in EBL_Name strings like:\n",
    "#   EBLN-Orthobornavirus.1-AotNan, EBLX-Carbovirus.3-Myotis_..., EBLP-Cultervirus...\n",
    "def extract_genus(s):\n",
    "    m = re.search(r\"EBL\\w*-([A-Za-z]+)\", str(s))\n",
    "    return m.group(1) if m else None\n",
    "\n",
    "df[\"Virus_Genus\"] = df[\"EBL_Name\"].apply(extract_genus)\n",
    "df = df.dropna(subset=[\"Virus_Genus\"])\n",
    "# Standardize capitalization (Orthobornavirus/Carbovirus/Cultervirus)\n",
    "df[\"Virus_Genus\"] = df[\"Virus_Genus\"].str.strip().str.capitalize()\n",
    "\n",
    "# Inspect\n",
    "df.head()\n",
    "\n",
    "\n",
    "# Count loci per host species x genus\n",
    "wide = (\n",
    "    df.groupby([\"Host_species\",\"Virus_Genus\"])\n",
    "      .size()\n",
    "      .unstack(fill_value=0)\n",
    "      .reset_index()\n",
    ")\n",
    "\n",
    "# Make sure all three columns exist even if absent in this subset\n",
    "for g in [\"Orthobornavirus\",\"Carbovirus\",\"Cultervirus\"]:\n",
    "    if g not in wide.columns:\n",
    "        wide[g] = 0\n",
    "\n",
    "# Add total\n",
    "wide[\"Total_EBLs\"] = wide[[\"Orthobornavirus\",\"Carbovirus\",\"Cultervirus\"]].sum(axis=1)\n",
    "\n",
    "# Keep only species with at least one EBL\n",
    "wide = wide[wide[\"Total_EBLs\"] > 0].copy()\n",
    "\n",
    "# Save to CSV (so you can reuse without re-parsing)\n",
    "wide_path = \"EBL_counts_per_species.csv\"\n",
    "wide.to_csv(wide_path, index=False)\n",
    "print(\"Wrote:\", wide_path)\n",
    "wide.head()\n",
    "\n",
    "import re\n",
    "\n",
    "def normalize_name(s):\n",
    "    return re.sub(r\"[^a-z ]\", \"\", str(s).lower().replace(\"_\", \" \")).strip()\n",
    "\n",
    "wide[\"merge_key\"] = wide[\"Host_species\"].apply(normalize_name)\n",
    "mammals[\"merge_key\"] = mammals[\"Scientific name\"].apply(normalize_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
